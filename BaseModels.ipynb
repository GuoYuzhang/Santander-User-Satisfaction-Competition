{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame as df\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNC\n",
    "from sklearn.decomposition import PCA, NMF\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_validate,GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier as MLP\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_validate,GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA, QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.ensemble import RandomForestClassifier as rf\n",
    "from sklearn.ensemble import ExtraTreesClassifier as et\n",
    "from xgboost import XGBClassifier as xgb\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/apple/anaconda/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Users/apple/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:15: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"train_12_3.csv\")\n",
    "valid = pd.read_csv(\"valid_12_3.csv\")\n",
    "\n",
    "train = train.append(valid)\n",
    "train_X = train.drop(columns = [\"TARGET\",\"ID\"])\n",
    "train_Y = train[\"TARGET\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_X = pd.DataFrame(scaler.fit_transform(train_X), columns=train_X.columns)\n",
    "# print(train.shape)\n",
    "\n",
    "test = pd.read_csv(\"test_12_3.csv\")\n",
    "test_X = test.drop(columns = [\"TARGET\",\"ID\"])\n",
    "test_Y = test[\"TARGET\"]\n",
    "test_X = pd.DataFrame(scaler.transform(test_X), columns=train_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all 149 features\n",
    "train_X_149=train_X.copy()\n",
    "test_X_149=train_X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#only 10 PCs 60% variance\n",
    "n_comp=10\n",
    "pca10=PCA(n_components=n_comp)\n",
    "pca10.fit(train_X)\n",
    "train_X_pca10=df(pca10.transform(train_X))\n",
    "test_X_pca10=df(pca10.transform(test_X))\n",
    "\n",
    "#only 76 PCs 99% variance\n",
    "n_comp=76\n",
    "pca76=PCA(n_components=n_comp)\n",
    "pca76.fit(train_X)\n",
    "train_X_pca76=df(pca76.transform(train_X))\n",
    "test_X_pca76=df(pca76.transform(test_X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "extraTree=et(n_estimators=100,min_samples_split=11,n_jobs=-1)\n",
    "extraTree.fit(train_X,train_Y)\n",
    "importance={}\n",
    "for i,imp in enumerate(extraTree.feature_importances_):\n",
    "    importance[train_X.columns[i]]=imp\n",
    "features2use=[]\n",
    "sorted_features=[]\n",
    "for i,f in enumerate(sorted(importance.items(),key=lambda x:-x[1])):\n",
    "    sorted_features.append(f[0])\n",
    "    if i<50:\n",
    "        features2use.append(f[0])\n",
    "    \n",
    "# for f in sorted(importance.items(),key=lambda x:-x[1])[:50]:\n",
    "#     features2use.append(f[0])\n",
    "    \n",
    "train_X_pca10top50=train_X.loc[:,features2use]\n",
    "test_X_pca10top50=test_X.loc[:,features2use]\n",
    "for col in train_X_pca10.columns:\n",
    "    train_X_pca10top50['PCA',col]=train_X_pca10.loc[:,col]\n",
    "    test_X_pca10top50['PCA',col]=test_X_pca10.loc[:,col]\n",
    "    \n",
    "train_X_pca2top10=train_X.loc[:,features2use[:10]]\n",
    "test_X_pca2top10=test_X.loc[:,features2use[:10]]\n",
    "for col in train_X_pca10.columns[:2]:\n",
    "    train_X_pca2top10['PCA',col]=train_X_pca10.loc[:,col]\n",
    "    test_X_pca2top10['PCA',col]=test_X_pca10.loc[:,col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature2non_dominate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "contri=df(pca10.components_,columns=train_X.columns,index = ['PC1','PC2','PC3','PC4','PC5','PC6','PC7','PC8','PC9','PC10'])\n",
    "contri_list = [(contri[col]**2).sum() for col in contri.columns]\n",
    "contri_dict={}\n",
    "for i,val in enumerate(contri_list):\n",
    "    contri_dict[contri.columns[i]]=val\n",
    "contri_dict=sorted(contri_dict.items(),key=lambda x:-x[1])\n",
    "feature2avoid=[entry[0] for i,entry in enumerate(contri_dict) if i<15]\n",
    "feature2non_dominate=[i for i in sorted_features if i not in feature2avoid][:50]\n",
    "\n",
    "train_X_pca10next50=train_X.loc[:,feature2non_dominate]\n",
    "test_X_pca10next50=test_X.loc[:,feature2non_dominate]\n",
    "for col in train_X_pca10.columns:\n",
    "    train_X_pca10next50['PCA',col]=train_X_pca10.loc[:,col]\n",
    "    test_X_pca10next50['PCA',col]=test_X_pca10.loc[:,col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_base_model(X,y,testX,testY):\n",
    "    models2consider = [['DecisionTree', DecisionTreeClassifier(), {'max_depth':[3,5,7,9,11,13,15,17,19,21],'min_samples_leaf':[10,20,30,40,100,200,500,1000,2000]}],\n",
    "                       ['logistic',LogisticRegression(solver='saga', max_iter=2000),{'penalty':['l1','l2'],'C':[0.01,0.1,0.5,1,1.5,2,5,10]}],\n",
    "                       ['kNN',KNC(),{'n_neighbors':[1,3,5,10,20,50,100,500], 'p': [1,2,3]}],\n",
    "                       ['LDA', LDA(),{'shrinkage':['auto', 0.01, 0.1,0.3, 0.6], 'solver': ['lsqr', 'eigen']}],\n",
    "                       ['QDA',QDA(), {'reg_param':[0.001, 0.01, 0.1, 0.3, 0.6]}],\n",
    "                       ['SVM',SVC(probability=True), {'C':[0.01,0.1,1,5,10,100,1000]}],\n",
    "                       ['MLP',MLP(), {'activation':['tanh', 'relu'], 'hidden_layer_sizes': [8, 16, 32, [32,16], [16, 8],[16,8,4]], 'learning_rate_init':[0.001,0.01,0.1]}],\n",
    "                       ['XGB',xgb(), {'max_depth': [3,9,15,21], 'n_estimators':[10,30,50,100,300], 'learning_rate':[0.001,0.01,0.1]}],\n",
    "                       ['RF', rf(), {'n_jobs':[-1],'n_estimators': [10, 50, 100, 200, 500], 'max_depth': [3, 5, 7, 9, 11, 13, 15, 17, 19, 21], 'min_samples_leaf': [10, 20, 30, 40, 100, 200, 500, 1000, 2000]}]]\n",
    "\n",
    "    allmodel_resu = []\n",
    "    for i in range(len(models2consider)):\n",
    "\n",
    "        model_name = models2consider[i][0]\n",
    "        clf = models2consider[i][1]\n",
    "        parameters = models2consider[i][2]\n",
    "\n",
    "        print(model_name)\n",
    "\n",
    "        model_resu = {'name':model_name}\n",
    "        CVresu = GridSearchCV(clf,parameters,cv = 3,scoring='roc_auc',return_train_score=False)\n",
    "        CVresu = CVresu.fit(X, y)\n",
    "        best = CVresu.best_estimator_ \n",
    "        model_resu['best_param'] = CVresu.best_params_\n",
    "        model_resu['best_CV_AUC'] = CVresu.best_score_\n",
    "        model_resu['test_AUC'] = roc_auc_score(test_y ,best.predict_proba(testX)[:,1])\n",
    "        print(model_resu)\n",
    "        allmodel_resu.append(model_resu)\n",
    "    return allmodel_resu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_149=train_base_model(train_X_149,train_Y,test_X_149,test_Y)\n",
    "result_pca10=train_base_model(train_X_pca10,train_Y,test_X_pca10,test_Y)\n",
    "result_pca76=train_base_model(train_X_pca76,train_Y,test_X_pca76,test_Y)\n",
    "result_pca10top50=train_base_model(train_X_pca10top50,train_Y,test_X_pca10top50,test_Y)\n",
    "result_pca2top10=train_base_model(train_X_pca2top10,train_Y,test_X_pca2top10,test_Y)\n",
    "result_pca10next50=train_base_model(train_X_pca10next50,train_Y,test_X_pca10next50,test_Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
